{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config memory to the session, incase needs the space for training\n",
    "spark = SparkSession.builder.appName(\"NYC Yellow Taxi Analysis\")\\\n",
    "                            .config(\"spark.driver.memory\", \"12g\")\\\n",
    "                            .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read files to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset in .parquet format\n",
    "import os\n",
    "\n",
    "path = 'raw_data'\n",
    "parquet_file_name = os.listdir(path)\n",
    "\n",
    "raw_data = []\n",
    "\n",
    "for file_name in parquet_file_name:\n",
    "    parquet_path = os.path.join(path, file_name)\n",
    "    raw_data.append(spark.read.parquet(parquet_path))\n",
    "\n",
    "zone_table_path = 'taxi_zone_lookup.csv'\n",
    "zone_df = spark.read.option('header', 'true').csv(zone_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the datatype for January data to make sure the consistent\n",
    "from pyspark.sql.types import IntegerType, DoubleType, LongType\n",
    "\n",
    "raw_data[0] = raw_data[0].withColumn('VendorID', raw_data[0]['VendorID'].cast(IntegerType()))\\\n",
    "                        .withColumn('passenger_count', raw_data[0]['passenger_count'].cast(LongType()))\\\n",
    "                        .withColumn('RatecodeID', raw_data[0]['RatecodeID'].cast(LongType()))\\\n",
    "                        .withColumn('PULocationID', raw_data[0]['PULocationID'].cast(IntegerType()))\\\n",
    "                        .withColumn('DOLocationID', raw_data[0]['DOLocationID'].cast(IntegerType()))\n",
    "\n",
    "# change the zone to integer\n",
    "zone_df = zone_df.withColumn('LocationID', zone_df['LocationID'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union the raw data into one df\n",
    "df = raw_data[0]\n",
    "\n",
    "for i in range(1, len(raw_data)):\n",
    "    df = df.union(raw_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLLib (WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the total amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour, minute, second\n",
    "\n",
    "preprocess_time = df.withColumn(\"PU hour\", hour(\"tpep_pickup_datetime\")) \\\n",
    "                    .withColumn(\"PU minute\", minute(\"tpep_pickup_datetime\")) \\\n",
    "                    .withColumn(\"DO hour\", hour(\"tpep_dropoff_datetime\")) \\\n",
    "                    .withColumn(\"DO minute\", minute(\"tpep_dropoff_datetime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the necessary column data\n",
    "selected_column = preprocess_time.select(\"PU hour\", \"PU minute\",\"DO hour\", \"DO minute\",\n",
    "                            \"trip_distance\", \"passenger_count\", \"PULocationID\",\n",
    "                            \"DOLocationID\", \"tolls_amount\", \"total_amount\")\n",
    "\n",
    "# dropna values if any\n",
    "selected_column = selected_column.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature vector\n",
    "feature_columns = [\"PU hour\", \"PU minute\",\"DO hour\", \"DO minute\",\n",
    "                            \"trip_distance\", \"passenger_count\", \"PULocationID\", \n",
    "                            \"DOLocationID\", \"tolls_amount\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "transform_df = assembler.transform(selected_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and testing set by ratio\n",
    "train_df, test_df = transform_df.randomSplit([0.8, 0.2], seed=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the linear regression model\n",
    "linear = LinearRegression(featuresCol='features', labelCol='total_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "linear_model = linear.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prediction\n",
    "predictions = linear_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-------+---------+-------------+---------------+------------+------------+------------+------------+--------------------+------------------+\n",
      "|PU hour|PU minute|DO hour|DO minute|trip_distance|passenger_count|PULocationID|DOLocationID|tolls_amount|total_amount|            features|        prediction|\n",
      "+-------+---------+-------+---------+-------------+---------------+------------+------------+------------+------------+--------------------+------------------+\n",
      "|      0|        0|      0|        0|          0.0|              1|          97|          97|         0.0|        36.0|(9,[5,6,7],[1.0,9...|24.568276416418758|\n",
      "|      0|        0|      0|        0|          0.0|              1|         107|         107|         0.0|        16.2|(9,[5,6,7],[1.0,1...|24.247984578267165|\n",
      "|      0|        0|      0|        0|          0.0|              1|         234|         264|         0.0|        6.88|(9,[5,6,7],[1.0,2...|  19.8341059268232|\n",
      "|      0|        0|      0|        1|          0.0|              1|         265|         265|         0.0|        56.0|(9,[3,5,6,7],[1.0...|19.185248074153545|\n",
      "|      0|        0|      0|        1|          0.1|              1|         107|         107|         0.0|         8.7|[0.0,0.0,0.0,1.0,...|24.246693614797884|\n",
      "|      0|        0|      0|        1|         0.31|              1|          48|          48|         0.0|         8.7|[0.0,0.0,0.0,1.0,...|26.138167905375546|\n",
      "|      0|        0|      0|        1|         0.42|              1|          48|          48|         0.0|       11.28|[0.0,0.0,0.0,1.0,...|26.139085853009636|\n",
      "|      0|        0|      0|        2|         0.02|              1|         148|         148|         0.0|         8.7|[0.0,0.0,0.0,2.0,...|22.930704018778563|\n",
      "|      0|        0|      0|        2|         0.31|              1|          48|          48|         0.0|       11.75|[0.0,0.0,0.0,2.0,...|26.136042444057093|\n",
      "|      0|        0|      0|        2|         0.48|              1|         161|         161|         0.0|       12.12|[0.0,0.0,0.0,2.0,...|22.518163319287687|\n",
      "|      0|        0|      0|        3|         0.41|              1|          79|          79|         0.0|       12.62|[0.0,0.0,0.0,3.0,...|25.141846782317877|\n",
      "|      0|        0|      0|        3|         0.55|              1|         263|         141|         0.0|        12.1|[0.0,0.0,0.0,3.0,...|20.657412638786948|\n",
      "|      0|        0|      0|        3|         0.59|              1|         261|          13|         0.0|       12.96|[0.0,0.0,0.0,3.0,...| 22.17572849461564|\n",
      "|      0|        0|      0|        3|          0.6|              1|         236|         236|         0.0|        20.1|[0.0,0.0,0.0,3.0,...|20.114850469251294|\n",
      "|      0|        0|      0|        3|         0.67|              1|         234|         107|         0.0|       12.96|[0.0,0.0,0.0,3.0,...| 21.64495575133203|\n",
      "|      0|        0|      0|        3|         0.68|              1|         249|          68|         0.0|       12.96|[0.0,0.0,0.0,3.0,...| 21.78771159634329|\n",
      "|      0|        0|      0|        3|         0.69|              2|         230|          48|         0.0|       -10.8|[0.0,0.0,0.0,3.0,...| 22.87258029237315|\n",
      "|      0|        0|      0|        3|          0.7|              1|         170|         100|         0.0|        12.1|[0.0,0.0,0.0,3.0,...|23.037346481711374|\n",
      "|      0|        0|      0|        3|          0.7|              4|         229|         233|         0.0|        12.1|[0.0,0.0,0.0,3.0,...|  21.6878079767963|\n",
      "|      0|        0|      0|        3|         0.74|              2|         264|         229|         0.0|       12.96|[0.0,0.0,0.0,3.0,...|  20.0877609876805|\n",
      "+-------+---------+-------+---------+-------------+---------------+------------+------------+------------+------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"PU hour\", \"PU minute\",\"DO hour\", \"DO minute\",\n",
    "                            \"trip_distance\", \"passenger_count\", \"PULocationID\", \n",
    "                            \"DOLocationID\", \"tolls_amount\",\n",
    "                            \"total_amount\", \"prediction\").orderBy(col('trip_distance').desc())\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 46.969226\n",
      "R2: 0.111854\n"
     ]
    }
   ],
   "source": [
    "training_summary = linear_model.summary\n",
    "print(\"RMSE: %f\" % training_summary.rootMeanSquaredError)\n",
    "print(\"R2: %f\" % training_summary.r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
